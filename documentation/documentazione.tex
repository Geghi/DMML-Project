\documentclass[a4paper, oneside]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{frontespizio}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{scrextend}
\usepackage[margin=1.2in]{geometry}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{url}
\usepackage{hyperref}
\usepackage{verbatim}
\usepackage{xcolor}

\begin{document}
\selectlanguage{english}
\baselineskip 13pt
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
}

% ---- FRONTESPIZIO ----- 
\begin{frontespizio} 
\Preambolo{\renewcommand{\frontpretitlefont}{\fontsize{15}{12}\scshape}}
\Istituzione {University of Pisa}
\Divisione {Scuola di Ingegneria}
\Corso [Laurea]{Artificial Intelligence and Data Engineering}
\Annoaccademico {2019--2020}
\Titolo {Task2 documentation}
\Filigrana [height=4cm,before=0.28,after=1]{./images/stemma_unipi.png}
\Rientro {1cm}
\Candidato {Giacomo Mantovani}
\Candidato {Stefano Poleggi}
\Relatore {Prof. Pietro Ducange}
 \Punteggiatura {}
\end{frontespizio}


\clearpage


% ----- INDICE -----
	\tableofcontents\thispagestyle{empty}
	\clearpage


\section{Introduction}\pagenumbering{arabic}
The \textbf{TweetQuake} application offers a real-time serious earthquake detection service in Italy. When the application opens up it will start fetching tweets and analyzing them to recognize ones related to an earthquake.
The application will show the number of earthquake tweets recognized so far. When some earthquake tweets are recognized the application show a warning message, if there is a trend of earthquake tweets then the application will show an emergency message. If the button at the end of the page is clicked then a new window containing the last recognized earthquakes opens up.
\vspace{5mm}
\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{./images/diagrams/HomeMockup} 
\caption{Home Page Mockup}
\label{fig:mockup}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{./images/diagrams/Charts} 
\caption{Results Page Mockup}
\label{fig:mockup}
\end{figure}

\clearpage

\section{Analysis and workflow}

% ----- REQUIREMENTS -----
\subsection{Requirements}

\subsubsection{Functional requirement}
The system has to allow the user to carry out basic functions such as:
\begin{itemize}
\item To start the real-time fetching.
\item To stop the real-time fetching.
\item To view the most recent recognized earthquakes from the application.
\end{itemize}
\vspace{2mm}
The system has to iteratively perform the following operations: 
\begin{itemize}
\item Real-time fetching of tweets.
\item Perform a classification of the tweets and obtain the label (earthquake or non-earthquake).
\item When some earthquake tweet is regocnized show a warning message.
\item When an earthquake tweet trend is recognized show an emergency message and add the relative earthquake information into the database.
\end{itemize}
\vspace{2mm}

\subsubsection{Non-functional requirements}
\begin{itemize}
\item Usability, ease of use and intuitiveness of the application by the user.
\item The system should provide a high level of accuracy.
\end{itemize}

\clearpage

% ----- USE CASES -----
\subsection{Use Cases}

\textbf{Actors}
\begin{itemize}
\item{User: this actor represents a user of the application}
\item{System: this actor represent the system}
\item{Twitter: this actor represent the Twitter service}
\end{itemize}

\subsubsection{Use Cases Description}
\begin{itemize}
\item Twitt Search : This use case can be performed by the user to start the real-time tweets fetching.
\item Retrive Tweet: This use case represents the action of getting a tweet from twitter.
\item Twitter Connection: This use case represents the connection with the Twitter service.
\item HTTP Request for Connection: This use case represents the Request for the connection to the Twitter Service.
\item HTTP Response for Connection: This use case represents the Response for the connection from the Twitter Service.
\item HTTP Request for Tweets: This use case represents the Request for tweets to the Twitter service.
\item HTTP Response for tweets: This use case represents the Response for tweets from the Twitter service.
\item Perform Text Analysis: This use case represents the process of Text analysis performed by the system.
\item Apply Classification Algorithm: This use case represents the classification of the tweets performed with the previously generated classifier by the "Generate Classifier" use case.
\item Show Warning Message: This use case displays an warning message if a few earthquake tweet are recognized.
\item Show Emergency Message: This use case displays an emergency message if a some earthquake tweet are recognized.
\item Add Earthquake To Database: This use case represent the insert of the recognized earthquake into the database.
\item Display Results: This use case shows the results of the classification.
\item Browse earthquakes: The system browses the earthquakes on the database.
\item Find earthquake: The system selects an earthquake on the database.
\item Display Earthquake: This use case shows the earthquake on the application.
\item Generate Classifier: This use case is performed automatically by the system and it generates a classifier using a training set. 
\item Browse Tweets: The system browses the tweets on the trainig dataset.
\item Train the classifier: Perform an algorithm to generate the classifier.
\item Stop Real-Time fetching: This use case allows the user to stop the real-time tweets fetching.
\end{itemize}

\begin{minipage}{\linewidth}
\begin{center}
\vspace{8mm}
\includegraphics[ width=0.55\textheight]{./images/diagrams/UseCase} 
\captionof{figure}{Use cases diagram}
\vspace{3mm}
\end{center}
\end{minipage}


\clearpage
\subsection{System Flow Diagram}
\begin{minipage}{\linewidth}
\begin{center}
\vspace{8mm}
\includegraphics[ width=0.6\textheight]{./images/diagrams/Flow Diagram} 
\captionof{figure}{Flow Diagram}
\vspace{3mm}
\end{center}
\end{minipage}

\clearpage
\subsection{Text analysis process}
\begin{minipage}{\linewidth}
\begin{center}
\vspace{8mm}
\includegraphics[ width=0.13\textheight]{./images/diagrams/Process} 
\captionof{figure}{Text Analysis Process}
\vspace{3mm}
\end{center}
\end{minipage}

\clearpage
\subsection{Data analysis}
\subsubsection{Building the classifier}
In order to build our classifier raw tweets have been scraped using a twitter scraping tool called Twint written in Python. Given location, tags to search for and a timestamp  (or a date interval), returns the informations about the tweets matching those parameters. For more information visit: \textcolor{blue}{\href{https://www.github.com/twintproject/twint}{Twint Github Page}}. To build the training set two different queries have been used: 
\begin{itemize}
\item The first query selects the tweets in Italy matching the keyword "terremoto".
\item The second query selects the tweets in Italy without tags.
\end{itemize} 
After that the labels (earthquake, non-earthquake) have been added manually to obtain a good training (and test) set to generate a classifier. We ended up with a balanced dataset of about 300 tweets per class, 600 labeled tweets.\\
The training data will be stored in an arff file, after cleaning the text of the tweet. The second query is necessary to obtain better results because without the tweets obtained from it the classifier would suffer from overfitting.\\
Once the training data is ready a classification algorithm is applied in order to build the classifier.

\subsubsection{2016-2017 earthquakes database}
Another database was created by collecting (in the same way) tweets between the dates 2017-06-30 and 2016-06-01. With that database we managed to create an histogram to check if there are spikes of tweets corresponding to catastrofic earthquakes in order to perform an analysis. The total number of analyised tweets is 304307.

\begin{minipage}{\linewidth}
\begin{center}
\vspace{8mm}
\includegraphics[ width=0.6\textheight]{./images/images/2016-2017 unlabeled} 
\captionof{figure}{2016-2017 tweets}
\vspace{3mm}
\end{center}
\end{minipage}
As we can see there are 3 major spikes relative to the 24-08-2016, 30-10-2016 and 18-01-2017 huge earthquakes. We created the same histogram after performing a classification on the tweets using the classifier obtained from the training set.

\clearpage
\subsubsection{Application parameters}
Two parameters are used in this application:
\begin{itemize}
\item Number of tweets classified as "earthquake" to detect before sending a warning message (Warning threshold).
\item Number of tweets classified as "earthquake" to detect before sending an emergency message (Emergency threshold).
\end{itemize}
We tested how many earthquake tweets are detected in a 10 minutes time span of a real serious earthquake, a non serius earthquake and a random time span without any earthquake. After that, the threshold values have been setted based on the values obtained from the tests.

\clearpage
\subsection{Model analysis}
\subsubsection{Choosing the classifier}
The choice of the classifier has been made by evaluating some quality measures of different classifiers applying a 10-fold cross-validation to find the best one for our application. We performed a cost sensitive classification schema, because we wanted to give an higher misclassification error cost for the “earthquake” class rather than “non earthquake” class. 

\begin{minipage}{\linewidth}
\begin{center}
\vspace{8mm}
\includegraphics[ width=0.23\textheight]{./images/images/costMatrix} 
\captionof{figure}{Cost matrix.}
\vspace{3mm}
\end{center}
\end{minipage}


The results obtained from the different classifiers is show in the figure below.

\begin{minipage}{\linewidth}
\begin{center}
\vspace{8mm}
\includegraphics[ width=0.6\textheight]{./images/images/classifiers accuracy} 
\captionof{figure}{confusion matrix}
\vspace{3mm}
\end{center}
\end{minipage}
We ended up choosing the SMO classifier since it has the higher accuracy and the number of false negative is fairly low, which is good in our case since we don’t want to classify non earthquake tweets as earthquake, but it is acceptable to have a slightly higher number of false positive (this is the reason for applying the cost sensitive classifier to our model).
The confusion matrix obtained from the classification is the following:

\begin{minipage}{\linewidth}
\begin{center}
\vspace{8mm}
\includegraphics[ width=0.3\textheight]{./images/images/confMatrixSMO} 
\captionof{figure}{classifiers accuracy}
\vspace{3mm}
\end{center}
\end{minipage}


\clearpage
% ----- DESIGN -----
\section{Design}

\subsection{Software architecture}
The application is designed over 3 different layers, see figure \ref{fig:architecture_diagram}:
\begin{itemize}
\item Front-end
\item Middleware
\item Back-end
\end{itemize}
\vspace{5mm}
\begin{minipage}{\linewidth}
\begin{center}
\vspace{1mm}
\includegraphics[height = 100mm]{./images/diagrams/architecture} 
\vspace{6mm}
\captionof{figure}{Software architecture diagram\\}
\label{fig:architecture_diagram}
\end{center}
\end{minipage}
\vspace{7mm}
\clearpage


\clearpage
% ----- IMPLEMENTATION -----
\section{Implementation}
\subsection{Used technologies}
The application is developed in java programming language, version 11.0.4, and in JavaFX system to create the GUI, version 11, so it should run on each platform in which JVM is installed, but the application is tested and guardantee on Ubuntu 16 and Window OS. Moreover Maven is used  to build and mantain the project, version 3.8.0. \\
The java driver for mongo manage the comunication between client application layer and mongo backend layer, version 3.11.2.\\ 
For the background layer it is used Apache as web-server, version 2.4 (including MySql).\\
So this application is tested using these technologies, considering these particular versions: for other versions the correct execution isn't guaranteed.\\

\subsection{Building the classifier}
The following java-code shows the training part of the process to obtain our classifier using the SVM classification method.
\begin{verbatim}
			LovinsStemmer stemmer = new LovinsStemmer();

			WordsFromFile stopwordHandler = new WordsFromFile();
			File stopwordsFile = new File("./src/main/resources/stopwords_it.txt");
			stopwordHandler.setStopwords(stopwordsFile);

			StringToWordVector stringToWordVector = new StringToWordVector(1000);
			stringToWordVector.setOutputWordCounts(true);
			stringToWordVector.setStemmer(stemmer);
			stringToWordVector.setStopwordsHandler(stopwordHandler);

			InfoGainAttributeEval igAttributeEval = new InfoGainAttributeEval();
			Ranker ranker = new Ranker();
			ranker.setOptions(new String[] { "-T", "0.0" });

			AttributeSelection attSelect = new AttributeSelection();
			attSelect.setEvaluator(igAttributeEval);
			attSelect.setSearch(ranker);

			MultiFilter multiFilter = new MultiFilter();
			Filter[] twoFilters = new Filter[2];
			twoFilters[0] = stringToWordVector;
			twoFilters[1] = attSelect;
			multiFilter.setFilters(twoFilters);

			SMO smo = new SMO();
			CostSensitiveClassifier costSensitiveClassifier = new CostSensitiveClassifier();
			Reader reader = new BufferedReader(new FileReader("./costMatrix.cost"));
			CostMatrix costMatrix = new CostMatrix(reader);
			costSensitiveClassifier.setClassifier(smo);
			costSensitiveClassifier.setCostMatrix(costMatrix);

			FilteredClassifier fc = new FilteredClassifier();
			fc.setFilter(multiFilter);
			fc.setClassifier(costSensitiveClassifier);
			fc.buildClassifier(data);

\end{verbatim}


\subsection{Create}
Adding an earthquake to the database.
\vspace{2mm}
\begin{verbatim}
public void addDetectedEarthquake(Timestamp timestamp, double lat, double lon) {
    try {
        String position = lat + " " + lon;
        if (lat == 0 && lon == 0) {
            position = "NOT FOUND";
        }
        insertEarthquakeStatement.setTimestamp(1, timestamp);
        insertEarthquakeStatement.setString(2, position);
        int i = insertEarthquakeStatement.executeUpdate();
        System.out.println("Added " + i + " row");
    } catch (SQLException e) {
        e.printStackTrace();
    }
}
\end{verbatim}
\vspace{5mm}

\subsection{Read}
This functionality returns a list of tweets.
\vspace{2mm}
\begin{verbatim}
public List<Earthquake> getEarthquakesList(){
    List<Earthquake> list = new ArrayList<Earthquake>();
    Earthquake earthquake = null;	
    try {
        result = getLastDetectedStatement.executeQuery();
        while (result.next()) {
            Timestamp time = result.getTimestamp("Timestamp");
            String location = result.getString("Position");
            String timeString = time.toString();
            timeString = timeString.substring(0, timeString.length()-2);
            earthquake = new Earthquake(timeString, location);
            list.add(earthquake);
            if(list.size() >= 10)
                break;
        }
        return list;
    } catch (SQLException e) {
        e.printStackTrace();
    }
    return list;
}
\end{verbatim}
\vspace{5mm}

\subsection{Classification of tweets}
This functionality performs the classification of tweets and count the number of earthquake tweets recognized.
\vspace{2mm}
\begin{verbatim}
int count = 0;
for (int i = 0; i < data.numInstances(); i++) {
    String predictClass = trainingSet.classAttribute()
    .value((int) fc.classifyInstance(data.instance(i)));
    if (predictClass.equals("earthquake")) {
        count++;
    }
}
\end{verbatim}
\vspace{5mm}

\clearpage

\end{document}
